{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicamelo como si tuviera 5 años\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](images/architecture.png)\n",
    "\n",
    "En este cuaderno vamos a recorrer el proceso de configurar un chatbot simple en LangChain.\n",
    "\n",
    "A lo largo de este proceso, vamos a mostrar cómo LangSmith puede usarse para mejorar la experiencia del desarrollador en aplicaciones de IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos cargando nuestras variables de entorno desde el archivo .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "# Cargar las siguientes variables de entorno:\n",
    "# LANGSMITH_TRACING=true\n",
    "# LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# LANGSMITH_PROJECT=\"eli5-bot\"\n",
    "# LANGSMITH_API_KEY=\"<redacted>\"\n",
    "\n",
    "# OPENAI_API_KEY=\"<redacted>\"\n",
    "# TAVILY_API_KEY=\"<redacted>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuremos una herramienta llamada Tavily para permitir que nuestro asistente busque en la web al responder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(max_results=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diseñemos un prompt para RAG que usaremos a lo largo de todo el cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Template:  Sos un profesor y un experto en explicar temas complejos de una manera fácil de entender.\n",
      "Tu trabajo es responder la pregunta dada de forma tal que incluso un niño de 5 años pueda comprenderla.\n",
      "Se te ha proporcionado el contexto necesario para responder la pregunta.\n",
      "\n",
      "Pregunta: {question} \n",
      "\n",
      "Contexto: {context}\n",
      "\n",
      "Respuesta:\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Sos un profesor y un experto en explicar temas complejos de una manera fácil de entender.\n",
    "Tu trabajo es responder la pregunta dada de forma tal que incluso un niño de 5 años pueda comprenderla.\n",
    "Se te ha proporcionado el contexto necesario para responder la pregunta.\n",
    "\n",
    "Pregunta: {question} \n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Respuesta:\"\"\"\n",
    "print(\"Prompt Template: \", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando nuestra aplicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "openai_client = wrap_openai(OpenAI())\n",
    "\n",
    "@traceable\n",
    "def search(question):\n",
    "    web_docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in web_docs])\n",
    "    return web_results\n",
    "    \n",
    "@traceable\n",
    "def explain(question, context):\n",
    "    formatted = prompt.format(question=question, context=context)\n",
    "    \n",
    "    completion = openai_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": formatted},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "@traceable\n",
    "def eli5(question):\n",
    "    context = search(question)\n",
    "    answer = explain(question, context)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeando nuestra application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagina que la economía de un país es como un enorme parque de diversiones. En este parque, hay muchas atracciones, como montañas rusas, juegos de agua y carruseles. Ahora, la macroeconomía es como un grupo de personas que mira todo el parque desde arriba, en lugar de enfocarse solo en una atracción específica.\n",
      "\n",
      "La macroeconomía estudia cosas grandes y importantes sobre el parque entero, como cuántas personas vienen a divertirse, cuántas atracciones hay, si hay suficiente comida y bebida para todos, y si las entradas son baratas o caras. También se fija en si las personas están felices y trabajadoras para ayudar a que el parque funcione bien.\n",
      "\n",
      "Así que, en resumen, la macroeconomía es el estudio de cómo funciona toda la economía de un país, mirando todo en general en lugar de solo una parte.\n"
     ]
    }
   ],
   "source": [
    "question = \"Qué es la macroeconomía?\"\n",
    "print(eli5(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
